# Proyecto Integrador - Avance 3: Data Warehouse con dbt

Este documento consolida toda la informaci√≥n del proyecto de Data Engineering para e-commerce, incluyendo el pipeline ETL, modelo dimensional Kimball, transformaciones con dbt, y an√°lisis de datos.

## üìã Tabla de Contenidos

1. [Estructura del Proyecto](#estructura-del-proyecto)
2. [Inicio R√°pido](#inicio-r√°pido)
3. [Proyecto dbt](#proyecto-dbt)
4. [Capas de Transformaci√≥n](#capas-de-transformaci√≥n)
5. [Modelo Dimensional](#modelo-dimensional)
6. [Slowly Changing Dimensions (SCD)](#slowly-changing-dimensions-scd)
7. [Modelo F√≠sico (DDL)](#modelo-f√≠sico-ddl)
8. [Scripts SQL de Referencia](#scripts-sql-de-referencia)
9. [Integridad Referencial](#integridad-referencial)
10. [Vistas Anal√≠ticas y Storytelling](#vistas-anal√≠ticas-y-storytelling)
11. [Docker Setup](#docker-setup)
12. [Uso y Comandos](#uso-y-comandos)

---

## Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ data/                    # Datos fuente (CSV y SQL)
‚îú‚îÄ‚îÄ database/                # Conexi√≥n a base de datos
‚îú‚îÄ‚îÄ pipeline/                # Pipeline ETL
‚îÇ   ‚îú‚îÄ‚îÄ etl/                 # Scripts ETL
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Modelos ORM
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/           # Notebooks de an√°lisis
‚îÇ   ‚îî‚îÄ‚îÄ scripts/             # Scripts principales
‚îú‚îÄ‚îÄ dbt/                     # Proyecto dbt
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Modelos dbt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ staging/         # Modelos de staging (stg_*)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intermediate/    # Modelos intermedios (int_*)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marts/           # Modelos finales (marts)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fact/        # Tablas de hechos (fct_*)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dimension/   # Tablas de dimensiones (dim_*)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analytics/       # Vistas anal√≠ticas (vw_*)
‚îÇ   ‚îú‚îÄ‚îÄ snapshots/           # Snapshots para SCD Type 2
‚îÇ   ‚îú‚îÄ‚îÄ sql/                 # Scripts DDL del modelo f√≠sico
‚îÇ   ‚îú‚îÄ‚îÄ scripts/             # Scripts SQL de referencia (documentaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ docs/                # Documentaci√≥n adicional
‚îÇ   ‚îú‚îÄ‚îÄ macros/              # Macros de dbt
‚îÇ   ‚îî‚îÄ‚îÄ tests/               # Tests SQL personalizados
‚îú‚îÄ‚îÄ preguntas_negocio/       # Notebooks de an√°lisis de negocio
‚îú‚îÄ‚îÄ Dockerfile               # Dockerfile del proyecto
‚îú‚îÄ‚îÄ docker-compose.yml       # Docker Compose
‚îî‚îÄ‚îÄ env.example              # Variables de entorno de ejemplo
```

---

## Inicio R√°pido

### Opci√≥n 1: Con Docker (Recomendado)

```bash
# 1. Configurar variables de entorno (opcional)
cp env.example .env

# 2. Iniciar todos los servicios
docker-compose up -d

# 3. Acceder a servicios
# - PostgreSQL: localhost:5432
# - pgAdmin: http://localhost:8080
# - Jupyter: http://localhost:8888
# - dbt: docker-compose exec dbt bash
```

### Opci√≥n 2: Instalaci√≥n Local

```bash
# 1. Crear entorno virtual
python -m venv venv

# 2. Activar entorno virtual
# Windows:
.\venv\Scripts\Activate.ps1
# Linux/Mac:
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp env.example .env
# Editar .env con tus credenciales de PostgreSQL
```

---

## Proyecto dbt

### Configuraci√≥n

El proyecto dbt transforma los datos del e-commerce siguiendo las mejores pr√°cticas de ingenier√≠a de datos.

**Archivo de configuraci√≥n:** `dbt/dbt_project.yml`

**Variables del Proyecto:**
- `database`: Nombre de la base de datos (default: `avance_1_db`)
- `schema`: Esquema de la base de datos (default: `public`)

**Materializaci√≥n:**
- **Staging**: `view` (vistas para eficiencia)
- **Intermediate**: `view` (vistas para eficiencia)
- **Marts**: `table` (tablas para rendimiento en consultas)

### Dependencias

Este proyecto requiere:
- dbt-core
- dbt-postgres (adaptador para PostgreSQL)
- dbt-utils (para tests adicionales)

---

## Capas de Transformaci√≥n

### 1. Staging (stg_*)

Modelos que limpian y estandarizan los datos fuente. Cada modelo:
- Lee desde las tablas fuente (`source`)
- Aplica limpieza b√°sica (trim, upper, lower, regexp_replace)
- Valida datos (filtros, checks)
- Agrega campos calculados simples y flags de calidad

**T√©cnicas aplicadas:**
- Limpieza de texto: `TRIM`, `UPPER`, `LOWER`, `REGEXP_REPLACE`
- Normalizaci√≥n de formatos: DNI, email, c√≥digos postales
- Normalizaci√≥n num√©rica: redondeo, validaci√≥n de rangos
- Normalizaci√≥n de fechas: manejo de valores nulos, validaci√≥n de fechas futuras
- Manejo de valores nulos: `COALESCE`, valores por defecto
- Flags de calidad: `email_valido`, `dni_valido`, `precio_cero`, etc.

**Modelos:**
- `stg_usuarios` - Limpieza de datos de usuarios
- `stg_categorias` - Normalizaci√≥n de categor√≠as
- `stg_productos` - Limpieza y validaci√≥n de productos
- `stg_ordenes` - Normalizaci√≥n de √≥rdenes
- `stg_detalle_ordenes` - Validaci√≥n de detalles
- `stg_direcciones_envio` - Normalizaci√≥n de direcciones
- `stg_carrito` - Limpieza de carrito
- `stg_metodos_pago` - Normalizaci√≥n de m√©todos de pago
- `stg_ordenes_metodos_pago` - Validaci√≥n de pagos
- `stg_resenas_productos` - Limpieza de rese√±as
- `stg_historial_pagos` - Normalizaci√≥n de historial

### 2. Intermediate (int_*)

Modelos que combinan m√∫ltiples tablas de staging y realizan transformaciones m√°s complejas:
- Agregaciones
- Joins entre tablas
- C√°lculos de m√©tricas
- Preparaci√≥n para marts

**Modelos:**
- `int_ordenes_detalle` - Combina √≥rdenes con detalles y productos
- `int_ordenes_agregadas` - M√©tricas agregadas por orden
- `int_productos_resenas` - Productos con m√©tricas de rese√±as
- `int_usuarios_ordenes` - Usuarios con m√©tricas de √≥rdenes
- `int_ordenes_pagos` - √ìrdenes con informaci√≥n de pagos
- `int_ventas_diarias` - Agregaci√≥n de ventas por d√≠a
- `int_ventas_mensuales` - Agregaci√≥n de ventas por mes

### 3. Marts (fct_* y dim_*)

Modelos finales siguiendo el modelo dimensional de Kimball.

#### Tablas de Hechos (fct_*)
- `fct_ventas` - Hechos de ventas con m√©tricas de negocio
- `fct_pagos` - Hechos de pagos y transacciones
- `fct_resenas` - Hechos de rese√±as y calificaciones

#### Tablas de Dimensiones (dim_*)
- `dim_usuarios` - Dimensi√≥n de usuarios con segmentaci√≥n
- `dim_productos` - Dimensi√≥n de productos con m√©tricas
- `dim_categorias` - Dimensi√≥n de categor√≠as (SCD Type 1)
- `dim_metodos_pago` - Dimensi√≥n de m√©todos de pago (SCD Type 1)
- `dim_fecha` - Dimensi√≥n de fecha (tabla de fechas est√°tica)

---

## Modelo Dimensional

El proyecto implementa un modelo dimensional completo siguiendo la metodolog√≠a Kimball:

### Esquema Estrella

```
                    dim_fecha
                        ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ               ‚îÇ               ‚îÇ
    dim_usuarios    dim_productos   dim_categorias
        ‚îÇ               ‚îÇ               ‚îÇ
        ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ       ‚îÇ       ‚îÇ
        fct_ventas  ‚îÇ   fct_resenas
                    ‚îÇ
                fct_pagos
```

### Relaciones

**fct_ventas:**
- `usuario_id` ‚Üí `dim_usuarios.usuario_id`
- `producto_id` ‚Üí `dim_productos.producto_id`
- `categoria_id` ‚Üí `dim_categorias.categoria_id` (nullable)
- `fecha_venta_id` ‚Üí `dim_fecha.fecha_id`

**fct_pagos:**
- `usuario_id` ‚Üí `dim_usuarios.usuario_id`
- `metodo_pago_id` ‚Üí `dim_metodos_pago.metodo_pago_id`
- `fecha_pago_id` ‚Üí `dim_fecha.fecha_id`

**fct_resenas:**
- `usuario_id` ‚Üí `dim_usuarios.usuario_id`
- `producto_id` ‚Üí `dim_productos.producto_id`
- `fecha_resena_id` ‚Üí `dim_fecha.fecha_id`

**dim_productos:**
- `categoria_id` ‚Üí `dim_categorias.categoria_id` (nullable)

---

## Slowly Changing Dimensions (SCD)

El proyecto implementa diferentes tipos de SCD seg√∫n las necesidades de cada dimensi√≥n.

### SCD Type 1 (Sin Historial)

**Dimensiones:**
- `dim_categorias` - Las categor√≠as raramente cambian
- `dim_metodos_pago` - Los m√©todos de pago son estables
- `dim_fecha` - Dimensi√≥n est√°tica (pre-poblada)

**Caracter√≠sticas:**
- Los cambios sobrescriben los valores anteriores
- No se mantiene historial
- √ötil para datos que no requieren an√°lisis hist√≥rico

### SCD Type 2 (Con Historial Completo)

**Dimensiones:**
- `dim_productos_scd2` - Historial de precios, stock y categor√≠as
- `dim_usuarios_scd2` - Historial de segmentaci√≥n y m√©tricas

**Caracter√≠sticas:**
- Mantiene todas las versiones hist√≥ricas
- Cada cambio crea un nuevo registro
- Campos SCD:
  - `fecha_inicio_validez`: Fecha desde la cual la versi√≥n es v√°lida
  - `fecha_fin_validez`: Fecha hasta la cual la versi√≥n es v√°lida (9999-12-31 para actual)
  - `es_actual`: Indicador booleano de versi√≥n actual
  - `scd_id`: ID √∫nico del registro SCD

**Snapshots configurados:**
- `snap_productos` - Rastrea cambios en: `precio`, `stock`, `estado_stock`, `categoria_id`
- `snap_usuarios` - Rastrea cambios en: `segmento_cliente`, `total_ordenes`, `total_gastado`, `email`

**Estrategia:** `check` (detecta cambios en columnas espec√≠ficas)

**Modelos SCD:**
- `dim_productos_scd2` - Versi√≥n hist√≥rica de productos
- `dim_usuarios_scd2` - Versi√≥n hist√≥rica de usuarios
- `dim_productos_scd1` - Versi√≥n actual de productos (sin historial)
- `dim_usuarios_scd1` - Versi√≥n actual de usuarios (sin historial)

**Uso en Consultas:**

```sql
-- Obtener versi√≥n actual de un producto
SELECT * FROM dim_productos_scd2 
WHERE producto_id = 123 AND es_actual = true;

-- Obtener precio hist√≥rico de un producto en una fecha espec√≠fica
SELECT * FROM dim_productos_scd2 
WHERE producto_id = 123 
  AND '2024-01-15'::date BETWEEN fecha_inicio_validez::date 
                              AND fecha_fin_validez::date;
```

---

## Modelo F√≠sico (DDL)

El proyecto incluye scripts SQL DDL para crear el modelo f√≠sico del data warehouse directamente en PostgreSQL.

**Ubicaci√≥n:** `dbt/sql/`

**Scripts disponibles:**
- `00_create_all_tables.sql` - Script principal (ejecuta todos)
- `01_create_dimension_tables.sql` - Crea tablas de dimensiones
- `02_create_fact_tables.sql` - Crea tablas de hechos
- `03_create_indexes.sql` - Crea √≠ndices para optimizaci√≥n
- `04_create_foreign_keys.sql` - Crea foreign keys (opcional, comentadas por defecto)
- `05_populate_dim_fecha.sql` - Pobla tabla de fechas

**Orden de Ejecuci√≥n:**
1. `01_create_dimension_tables.sql` - Crea todas las tablas de dimensiones
2. `02_create_fact_tables.sql` - Crea todas las tablas de hechos
3. `03_create_indexes.sql` - Crea √≠ndices para optimizaci√≥n
4. `04_create_foreign_keys.sql` - Crea foreign keys (opcional)
5. `05_populate_dim_fecha.sql` - Pobla la tabla de dimensiones de fecha

**Tablas Creadas:**

**Dimensiones:**
- `dim_fecha` - Dimensi√≥n de tiempo (est√°tica)
- `dim_categorias` - Dimensi√≥n de categor√≠as (SCD Type 1)
- `dim_metodos_pago` - Dimensi√≥n de m√©todos de pago (SCD Type 1)
- `dim_productos` - Dimensi√≥n de productos (base)
- `dim_usuarios` - Dimensi√≥n de usuarios (base)
- `dim_productos_scd2` - Dimensi√≥n de productos con historial (SCD Type 2)
- `dim_usuarios_scd2` - Dimensi√≥n de usuarios con historial (SCD Type 2)

**Hechos:**
- `fct_ventas` - Hechos de ventas (tabla principal)
- `fct_pagos` - Hechos de pagos
- `fct_resenas` - Hechos de rese√±as

**Esquemas:**
- Las tablas se crean en el esquema `marts`
- `marts.dim_*` - Tablas de dimensiones
- `marts.fct_*` - Tablas de hechos

**√çndices:**
- Foreign keys (para joins eficientes)
- Campos de fecha (para filtros temporales)
- Campos de b√∫squeda frecuente (segmento_cliente, estado_stock, etc.)
- √çndices compuestos para consultas comunes

**Foreign Keys:**
- Est√°n **comentadas por defecto** para mejor performance en carga masiva
- Para habilitar, descomentar las l√≠neas en `04_create_foreign_keys.sql`

**Poblaci√≥n de dim_fecha:**
- Se puebla autom√°ticamente con el rango 2020-2030
- Para cambiar el rango, modificar la llamada a `populate_dim_fecha()` en `05_populate_dim_fecha.sql`

---

## Scripts SQL de Referencia

El proyecto incluye scripts SQL de referencia que documentan las t√©cnicas de transformaci√≥n utilizadas.

**Ubicaci√≥n:** `dbt/scripts/`

**Prop√≥sito:**
Estos scripts **NO se ejecutan directamente**. Son scripts de referencia y documentaci√≥n que muestran:
1. T√©cnicas de transformaci√≥n utilizadas en los modelos dbt
2. Ejemplos de c√≥digo SQL para cada tipo de transformaci√≥n
3. Mejores pr√°cticas y patrones comunes
4. Consultas de ejemplo para casos de uso comunes

**Scripts disponibles:**
- `01_limpieza_normalizacion.sql` - T√©cnicas de limpieza y normalizaci√≥n
- `02_creacion_hechos_dimensiones.sql` - Creaci√≥n de hechos y dimensiones
- `03_implementacion_scd.sql` - Implementaci√≥n de SCD Type 1 y Type 2

**Relaci√≥n con Modelos dbt:**
Estos scripts documentan las transformaciones que se implementan en:
- **Staging**: `models/staging/stg_*.sql`
- **Intermediate**: `models/intermediate/int_*.sql`
- **Marts**: `models/marts/fact/` y `models/marts/dimension/`
- **Snapshots**: `snapshots/snap_*.sql`

---

## Integridad Referencial

El proyecto incluye tests de relaciones para garantizar integridad referencial entre hechos y dimensiones.

**Archivos:**
- `models/marts/schema.yml` - Tests de relationships a nivel de columna
- `models/marts/relationships.yml` - Tests de integridad referencial a nivel de modelo
- `macros/validate_relationship.sql` - Macro para validar relaciones personalizadas
- `docs/RELACIONES.md` - Documentaci√≥n completa de relaciones

**Tests de Integridad Referencial:**

Los tests de `relationships` se definen en los archivos `schema.yml`:

```yaml
- name: usuario_id
  description: "ID del usuario (Foreign key a dim_usuarios)"
  tests:
    - relationships:
        to: ref('dim_usuarios')
        field: usuario_id
```

**Manejo de Valores Nulos:**
Algunas relaciones permiten valores NULL:
- `fct_ventas.categoria_id` puede ser NULL
- `dim_productos.categoria_id` puede ser NULL

Los tests incluyen cl√°usulas `where` para manejar estos casos:

```yaml
tests:
  - relationships:
      to: ref('dim_categorias')
      field: categoria_id
      config:
        where: "categoria_id IS NOT NULL"
```

**Orden de Ejecuci√≥n:**
dbt garantiza el orden correcto mediante:
1. **Dependencias impl√≠citas**: `ref()` y `source()` crean dependencias autom√°ticas
2. **Tests de relaciones**: Se ejecutan despu√©s de que los modelos est√°n listos
3. **Validaci√≥n**: Los tests fallan si hay valores hu√©rfanos

---

## Vistas Anal√≠ticas y Storytelling

El proyecto incluye vistas anal√≠ticas optimizadas y documentaci√≥n de storytelling para facilitar el an√°lisis y presentaci√≥n de insights.

### Vistas Anal√≠ticas (`models/analytics/`)

Vistas pre-agregadas optimizadas para an√°lisis r√°pidos:

- `vw_ventas_resumen` - Resumen de ventas con todas las dimensiones
- `vw_clientes_activos` - An√°lisis de comportamiento de clientes
- `vw_productos_performance` - Performance de productos
- `vw_ventas_temporales` - An√°lisis temporal con tendencias
- `vw_pagos_resumen` - Resumen de pagos y transacciones

**Caracter√≠sticas:**
- Vistas pre-agregadas para queries r√°pidas
- Optimizadas con √≠ndices y agregaciones
- Incluyen m√©tricas calculadas y segmentaciones

### Documentaci√≥n de Storytelling

**Archivos:**
- `docs/QUERIES_ANALISTAS.md` - Gu√≠a completa de queries para analistas (19 queries de ejemplo)
- `docs/STORYTELLING_INSIGHTS.md` - Insights en formato de storytelling con narrativa ejecutiva

**Formato Storytelling:**
- Presenta insights en formato narrativo
- Incluye situaci√≥n, insight y acci√≥n recomendada
- Proporciona queries SQL para explorar cada insight
- Organizado por categor√≠as de negocio (ventas, pagos, clientes, productos)

**Ejemplo de Query para Analistas:**

```sql
-- Productos m√°s vendidos por volumen
SELECT 
    producto_nombre,
    categoria_nombre,
    total_unidades_vendidas,
    total_ventas,
    total_ordenes
FROM marts.vw_productos_performance
ORDER BY total_unidades_vendidas DESC
LIMIT 10;
```

---

## Docker Setup

El proyecto est√° completamente containerizado usando Docker y Docker Compose.

### Servicios Disponibles

**PostgreSQL (db)**
- Imagen: postgres:16-alpine
- Puerto: 5432 (configurable)
- Vol√∫menes persistentes para datos
- Healthcheck configurado

**pgAdmin (pgadmin)**
- Interfaz web para gestionar PostgreSQL
- Puerto: 8080 (configurable)
- Acceso: http://localhost:8080
- Email: `admin@ecommerce.com` (configurable)
- Password: `admin` (configurable)

**dbt (dbt)**
- Contenedor con dbt y todas las herramientas
- Variables de entorno configuradas
- Vol√∫menes montados para el proyecto
- Listo para ejecutar comandos dbt

**Jupyter (jupyter)**
- Servidor Jupyter Lab
- Puerto: 8888 (configurable)
- Acceso: http://localhost:8888
- Sin token (configurado para desarrollo)

### Configuraci√≥n

**Variables de Entorno:**
Crear archivo `.env` basado en `env.example`:

```bash
cp env.example .env
```

Editar `.env` para personalizar:
- Credenciales de PostgreSQL
- Puertos de servicios
- Configuraciones de pgAdmin y Jupyter

**Perfiles de dbt:**
Los perfiles de dbt est√°n en `dbt_profiles/profiles.yml`. Se montan autom√°ticamente en el contenedor.

### Vol√∫menes

Los datos se persisten en vol√∫menes Docker:
- `postgres_data`: Datos de PostgreSQL
- `pgadmin_data`: Configuraci√≥n de pgAdmin
- `jupyter_data`: Configuraci√≥n de Jupyter

---

## Uso y Comandos

### Comandos dbt

```bash
# Compilar modelos
dbt compile

# Ejecutar modelos
dbt run

# Ejecutar solo staging
dbt run --select staging

# Ejecutar solo intermedios
dbt run --select intermediate

# Ejecutar solo marts
dbt run --select marts

# Ejecutar tests
dbt test

# Ejecutar snapshots (SCD Type 2)
dbt snapshot

# Generar documentaci√≥n
dbt docs generate
dbt docs serve
```

### Comandos Docker

```bash
# Iniciar servicios
docker-compose up -d

# Detener servicios
docker-compose down

# Ver logs
docker-compose logs -f

# Ejecutar dbt desde Docker
docker-compose exec dbt dbt run

# Ejecutar tests desde Docker
docker-compose exec dbt dbt test

# Ejecutar snapshots desde Docker
docker-compose exec dbt dbt snapshot

# Conectarse a PostgreSQL
docker-compose exec db psql -U usuario -d avance_1_db
```

### Ejecutar Scripts DDL

```bash
# Opci√≥n 1: Desde Docker
docker-compose exec db psql -U usuario -d avance_1_db -f /app/dbt/sql/00_create_all_tables.sql

# Opci√≥n 2: Localmente
psql -U usuario -d database -f dbt/sql/00_create_all_tables.sql

# Opci√≥n 3: Desde psql interactivo
\i dbt/sql/01_create_dimension_tables.sql
\i dbt/sql/02_create_fact_tables.sql
\i dbt/sql/03_create_indexes.sql
\i dbt/sql/04_create_foreign_keys.sql
\i dbt/sql/05_populate_dim_fecha.sql
```

### Flujo de Trabajo Recomendado

1. **Inicializaci√≥n:**
   ```bash
   # Iniciar servicios
   docker-compose up -d
   
   # Crear estructura de base de datos
   docker-compose exec db psql -U usuario -d avance_1_db -f /app/dbt/sql/00_create_all_tables.sql
   ```

2. **Desarrollo con dbt:**
   ```bash
   # Entrar al contenedor dbt
   docker-compose exec dbt bash
   
   # Navegar al directorio dbt
   cd /app/dbt
   
   # Ejecutar modelos
   dbt run
   
   # Ejecutar tests
   dbt test
   
   # Ejecutar snapshots
   dbt snapshot
   ```

3. **An√°lisis:**
   - Acceder a Jupyter: http://localhost:8888
   - Acceder a pgAdmin: http://localhost:8080
   - Consultar vistas anal√≠ticas desde cualquier cliente SQL

---

## Notas Importantes

- Los modelos de staging asumen que las tablas fuente est√°n en el esquema `public` por defecto
- Las tablas de hechos y dimensiones siguen el modelo dimensional de Kimball
- Se incluyen tests de calidad de datos en los modelos de staging
- Los modelos est√°n documentados con descripciones y tests en los archivos `schema.yml`
- Los SCD Type 2 mantienen historial completo de cambios para an√°lisis temporales
- Los scripts DDL crean el modelo f√≠sico directamente en PostgreSQL
- Los tests de relationships garantizan integridad referencial entre hechos y dimensiones
- Las vistas anal√≠ticas est√°n optimizadas para queries r√°pidas por parte de analistas
- El formato storytelling facilita la presentaci√≥n de insights a stakeholders

---

## Tecnolog√≠as Utilizadas

- **Python 3.10+**
- **PostgreSQL 16**
- **dbt** (Data Build Tool)
- **SQLAlchemy** (ORM)
- **Jupyter** (Notebooks)
- **Docker** (Containerizaci√≥n)
- **Docker Compose** (Orquestaci√≥n)

---

## Referencias

- [dbt Documentation](https://docs.getdbt.com/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Kimball Methodology](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/)
- [Docker Documentation](https://docs.docker.com/)
- [Docker Compose Documentation](https://docs.docker.com/compose/)

