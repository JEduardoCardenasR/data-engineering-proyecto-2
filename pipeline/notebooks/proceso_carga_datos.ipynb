{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proceso ETL - Carga de Datos a PostgreSQL (con Staging)\n",
        "\n",
        "Este notebook documenta el proceso completo de carga de datos desde archivos CSV a PostgreSQL usando el patrÃ³n de **staging area** (Ã¡rea de preparaciÃ³n).\n",
        "\n",
        "El proceso sigue las mejores prÃ¡cticas de ETL:\n",
        "1. **Carga datos crudos** a tablas staging (sin IDs, sin foreign keys)\n",
        "2. **Aplica transformaciones** sobre los datos en staging\n",
        "3. **Carga datos transformados** a producciÃ³n (con IDs autoincrementales y foreign keys)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ Resumen del Proceso\n",
        "\n",
        "El proceso ETL (Extract, Transform, Load) se ejecuta en **6 fases principales**:\n",
        "\n",
        "1. **Fase 1: Crear Tablas Staging** - Crea tablas staging usando SQL directo (sin IDs, sin foreign keys)\n",
        "2. **Fase 2: Cargar Datos Crudos a Staging** - Lee archivos CSV y carga datos sin transformar a staging\n",
        "3. **Fase 3: Crear Tablas de ProducciÃ³n** - Crea tablas de producciÃ³n usando SQLAlchemy ORM (con IDs, foreign keys, constraints)\n",
        "4. **Fase 4: Transformar Datos en Staging** - Aplica limpieza y transformaciones sobre datos en staging\n",
        "5. **Fase 5: Cargar Datos Transformados a ProducciÃ³n** - Transfiere datos desde staging a producciÃ³n con generaciÃ³n automÃ¡tica de IDs\n",
        "6. **Fase 6: Resolver Foreign Keys** - Mapea automÃ¡ticamente las referencias de staging a IDs de producciÃ³n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ Flujo de EjecuciÃ³n del CÃ³digo\n",
        "\n",
        "### Punto de Entrada: `main.py`\n",
        "\n",
        "El proceso comienza en `Avance1/main.py`, que actÃºa como orquestador principal:\n",
        "\n",
        "```python\n",
        "# 1. ConfiguraciÃ³n inicial de paths\n",
        "path_manager = PathManager.get_instance()  # Singleton\n",
        "path_manager.setup_sys_path()  # Configura sys.path\n",
        "\n",
        "# 2. Import de funciones\n",
        "from Models.create_tables import create_staging_tables, create_production_tables\n",
        "from ETL.load_raw_data import load_raw_data\n",
        "from ETL.transformations import apply_transformations\n",
        "from ETL.load_to_production import load_all_to_production\n",
        "\n",
        "# 3. EjecuciÃ³n del proceso\n",
        "def main():\n",
        "    # Paso 1: Crear tablas staging (SQL directo)\n",
        "    create_staging_tables()\n",
        "    \n",
        "    # Paso 2: Cargar datos crudos a staging\n",
        "    for config in tables_config:\n",
        "        load_raw_data(config['file'], config['table_raw'])\n",
        "    \n",
        "    # Paso 3: Crear tablas de producciÃ³n (ORM)\n",
        "    create_production_tables()\n",
        "    \n",
        "    # Paso 4: Transformar datos en staging\n",
        "    for config in tables_config:\n",
        "        df = pd.read_sql(f\"SELECT * FROM {config['table_raw']}\", engine)\n",
        "        df_transformed = apply_transformations(config['table_raw'], df)\n",
        "        # Actualizar staging con datos transformados\n",
        "    \n",
        "    # Paso 5-6: Cargar a producciÃ³n y resolver foreign keys\n",
        "    id_mappings = load_all_to_production()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1: CreaciÃ³n de Tablas Staging (`Models/create_tables.py`)\n",
        "\n",
        "**Flujo de ejecuciÃ³n:**\n",
        "\n",
        "1. **Leer archivo SQL:**\n",
        "   ```python\n",
        "   sql_file_path = 'Models/create_staging_tables.sql'\n",
        "   with open(sql_file_path, 'r', encoding='utf-8') as f:\n",
        "       sql_content = f.read()\n",
        "   ```\n",
        "\n",
        "2. **Ejecutar SQL directo:**\n",
        "   ```python\n",
        "   with engine.begin() as conn:\n",
        "       for statement in sql_statements:\n",
        "           conn.execute(text(statement))\n",
        "   ```\n",
        "   - Usa SQL directo (NO ORM) para crear tablas staging\n",
        "   - Las tablas staging NO tienen primary keys ni foreign keys\n",
        "   - Solo almacenan datos crudos tal como vienen del CSV\n",
        "   - Ejemplo: `usuarios_raw`, `productos_raw`, `ordenes_raw`\n",
        "\n",
        "### Paso 3: CreaciÃ³n de Tablas de ProducciÃ³n (`Models/create_tables.py`)\n",
        "\n",
        "**Flujo de ejecuciÃ³n:**\n",
        "\n",
        "1. **Obtener conexiÃ³n a la base de datos:**\n",
        "   ```python\n",
        "   db = DBConnector.get_instance()  # Singleton\n",
        "   engine = db.get_engine()\n",
        "   ```\n",
        "\n",
        "2. **Crear tablas usando ORM:**\n",
        "   ```python\n",
        "   for model in production_models:\n",
        "       model.__table__.create(engine, checkfirst=True)\n",
        "   ```\n",
        "   - Utiliza los modelos ORM definidos en `Models/models.py`\n",
        "   - Crea 11 tablas con IDs autoincrementales, foreign keys y constraints\n",
        "   - Aplica CheckConstraints para validaciones numÃ©ricas\n",
        "   - Crea tipos ENUM nativos de PostgreSQL para campos de estado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 2: Carga de Datos Crudos a Staging (`ETL/load_raw_data.py`)\n",
        "\n",
        "**Flujo de ejecuciÃ³n para cada archivo CSV:**\n",
        "\n",
        "1. **Obtener ruta del archivo CSV:**\n",
        "   ```python\n",
        "   csv_path = path_manager.get_csv_path(file_name)\n",
        "   # Ejemplo: 'DataSet/CSV/2.Usuarios.csv'\n",
        "   ```\n",
        "\n",
        "2. **Leer archivo CSV con pandas:**\n",
        "   ```python\n",
        "   df = pd.read_csv(csv_path, encoding=ETLConfig.CSV_ENCODING)  # 'utf-8'\n",
        "   ```\n",
        "\n",
        "3. **Estandarizar nombres de columnas:**\n",
        "   ```python\n",
        "   df.columns = [clean_column_name(col) for col in df.columns]\n",
        "   # Convierte camelCase a snake_case: 'OrdenID' -> 'orden_id'\n",
        "   ```\n",
        "\n",
        "4. **Filtrar columnas para staging:**\n",
        "   ```python\n",
        "   # Obtener columnas esperadas desde PostgreSQL (information_schema)\n",
        "   expected_columns = get_expected_columns(table_name_raw)\n",
        "   # Excluye automÃ¡ticamente columnas de ID primario si existen en el CSV\n",
        "   df_filtered = df[expected_columns]\n",
        "   ```\n",
        "\n",
        "5. **Insertar datos en staging usando COPY:**\n",
        "   ```python\n",
        "   with db.get_raw_connection() as conn:\n",
        "       cursor = conn.cursor()\n",
        "       # ... (mismo proceso COPY que antes)\n",
        "       cursor.copy_expert(\n",
        "           f\"COPY {table_name_raw} ({columns}) FROM STDIN WITH ...\",\n",
        "           csv_buffer\n",
        "       )\n",
        "   ```\n",
        "   - Usa el comando COPY nativo de PostgreSQL (mÃ¡xima eficiencia)\n",
        "   - Carga datos CRUDOS sin validaciones ni constraints\n",
        "   - Excluye automÃ¡ticamente columnas de ID primario del CSV\n",
        "\n",
        "### Paso 4: Transformaciones (`ETL/transformations.py`)\n",
        "\n",
        "**Transformaciones aplicadas por tabla:**\n",
        "\n",
        "- **usuarios_raw**: NormalizaciÃ³n de emails, trim de campos de texto\n",
        "- **categorias_raw**: Trim de nombre y descripciÃ³n\n",
        "- **productos_raw**: Trim, validaciÃ³n de precios y stock (no negativos)\n",
        "- **ordenes_raw**: CÃ¡lculo de totales desde detalle_ordenes_raw\n",
        "- **detalle_ordenes_raw**: ValidaciÃ³n de cantidades y precios (no negativos)\n",
        "- **resenas_productos_raw**: EliminaciÃ³n de duplicados por (usuario_id, producto_id)\n",
        "- **direcciones_envio_raw**: Trim de todos los campos de texto\n",
        "- **carrito_raw**: ValidaciÃ³n de cantidades (no negativas)\n",
        "- **metodos_pago_raw**: Trim de nombre y descripciÃ³n\n",
        "- **ordenes_metodos_pago_raw**: ValidaciÃ³n de montos (no negativos)\n",
        "- **historial_pagos_raw**: ValidaciÃ³n de montos (no negativos)\n",
        "\n",
        "### Paso 5-6: Carga a ProducciÃ³n (`ETL/load_to_production.py`)\n",
        "\n",
        "**Flujo de ejecuciÃ³n:**\n",
        "\n",
        "1. **Leer datos transformados de staging:**\n",
        "   ```python\n",
        "   df = pd.read_sql(f\"SELECT * FROM {source_table}\", engine)\n",
        "   ```\n",
        "\n",
        "2. **Resolver foreign keys:**\n",
        "   ```python\n",
        "   # Mapea IDs de staging a IDs de producciÃ³n usando identificadores naturales\n",
        "   df = resolve_foreign_keys(df, foreign_keys, id_mappings, engine)\n",
        "   ```\n",
        "\n",
        "3. **Insertar en producciÃ³n con generaciÃ³n automÃ¡tica de IDs:**\n",
        "   ```python\n",
        "   df.to_sql(target_table, engine, if_exists='append', index=False, method='multi')\n",
        "   ```\n",
        "\n",
        "4. **Crear mapeo de IDs:**\n",
        "   ```python\n",
        "   # Para tablas con natural_keys, crea mapeo: {natural_key: production_id}\n",
        "   # Ejemplo: {'nombre': 1, 'nombre2': 2} para categorias\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Resultado de la EjecuciÃ³n\n",
        "\n",
        "### Salida de la Consola\n",
        "\n",
        "```\n",
        "INICIANDO PROCESO ETL COMPLETO (STAGING â†’ TRANSFORMACIÃ“N â†’ PRODUCCIÃ“N)\n",
        "\n",
        "PASO 1/6: Creando tablas STAGING\n",
        "================================================================================\n",
        "CREANDO TABLAS STAGING (RAW) - Usando SQL directo\n",
        "================================================================================\n",
        "   âœ“ 11 tablas staging creadas/verificadas\n",
        "================================================================================\n",
        "âœ“ Todas las tablas staging creadas exitosamente (11 tablas)\n",
        "================================================================================\n",
        "\n",
        "PASO 2/6: Cargando datos crudos a STAGING\n",
        "================================================================================\n",
        "CARGANDO DATOS CRUDOS A STAGING: usuarios_raw\n",
        "   âœ“ Archivo leÃ­do. Filas: 1000, Columnas originales: 5\n",
        "   âœ“ Nombres de columnas estandarizados\n",
        "   âœ“ Columnas filtradas. Columnas a cargar: 5\n",
        "   âœ“ Datos cargados exitosamente a 'usuarios_raw' (1000 filas)\n",
        "[... similar para todas las tablas ...]\n",
        "\n",
        "PASO 3/6: Creando tablas de PRODUCCIÃ“N\n",
        "================================================================================\n",
        "CREANDO TABLAS DE PRODUCCIÃ“N\n",
        "   âœ“ Tabla 'categorias' creada/verificada\n",
        "   âœ“ Tabla 'metodos_pago' creada/verificada\n",
        "   [... todas las tablas de producciÃ³n ...]\n",
        "================================================================================\n",
        "âœ“ Todas las tablas de producciÃ³n creadas exitosamente (11 tablas)\n",
        "================================================================================\n",
        "\n",
        "PASO 4/6: Aplicando TRANSFORMACIONES sobre staging\n",
        "   Transformando: usuarios_raw\n",
        "      Normalizando 1000 emails...\n",
        "      âœ“ 379 emails normalizados\n",
        "   âœ“ TransformaciÃ³n de usuarios completada\n",
        "      âœ“ 1000 filas transformadas y actualizadas en usuarios_raw\n",
        "   \n",
        "   Transformando: ordenes_raw\n",
        "      Calculando totales desde detalle_ordenes...\n",
        "      âœ“ 1000 totales de Ã³rdenes corregidos\n",
        "   [... transformaciones para todas las tablas ...]\n",
        "\n",
        "PASO 5-6/6: Cargando datos a PRODUCCIÃ“N y resolviendo Foreign Keys\n",
        "================================================================================\n",
        "[1/11] Procesando: categorias_raw â†’ categorias\n",
        "   âœ“ Datos leÃ­dos de staging: 12 filas\n",
        "   Insertando 12 filas en 'categorias'...\n",
        "   âœ“ 12 filas insertadas exitosamente\n",
        "   Creando mapeo de IDs usando: ['nombre']\n",
        "[... similar para todas las tablas ...]\n",
        "\n",
        "âœ“ PROCESO ETL COMPLETADO EXITOSAMENTE\n",
        "================================================================================\n",
        "Resumen:\n",
        "   - Tablas staging creadas: 11\n",
        "   - Archivos CSV procesados: 11\n",
        "   - Tablas de producciÃ³n creadas: 11\n",
        "   - Transformaciones aplicadas: 11\n",
        "   - Tablas cargadas a producciÃ³n: 11\n",
        "   - Mapeos de IDs creados: 4\n",
        "   - Foreign keys resueltas: AutomÃ¡tico\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ EstadÃ­sticas del Proceso\n",
        "\n",
        "### Datos Cargados a Staging (Raw)\n",
        "\n",
        "| Archivo CSV | Tabla Staging | Filas Cargadas | Columnas |\n",
        "|-------------|---------------|----------------|----------|\n",
        "| `2.Usuarios.csv` | `usuarios_raw` | 1,000 | 5 |\n",
        "| `3.Categorias.csv` | `categorias_raw` | 12 | 2 |\n",
        "| `4.Productos.csv` | `productos_raw` | 36 | 5 |\n",
        "| `5.ordenes.csv` | `ordenes_raw` | 10,000 | 4 |\n",
        "| `6.detalle_ordenes.csv` | `detalle_ordenes_raw` | 10,000 | 4 |\n",
        "| `7.direcciones_envio.csv` | `direcciones_envio_raw` | 1,000 | 9 |\n",
        "| `8.carrito.csv` | `carrito_raw` | 5,000 | 4 |\n",
        "| `9.metodos_pago.csv` | `metodos_pago_raw` | 7 | 2 |\n",
        "| `10.ordenes_metodospago.csv` | `ordenes_metodos_pago_raw` | 10,000 | 3 |\n",
        "| `11.resenas_productos.csv` | `resenas_productos_raw` | 7,172 | 5 |\n",
        "| `12.historial_pagos.csv` | `historial_pagos_raw` | 10,000 | 5 |\n",
        "\n",
        "**Total a Staging:** 55,227 registros cargados en 11 tablas staging\n",
        "\n",
        "### Transformaciones Aplicadas\n",
        "\n",
        "| Tabla | Transformaciones | Resultado |\n",
        "|-------|------------------|-----------|\n",
        "| `usuarios_raw` | NormalizaciÃ³n de emails, trim | 379 emails normalizados |\n",
        "| `ordenes_raw` | CÃ¡lculo de totales desde detalle_ordenes | 1,000 totales corregidos |\n",
        "| `resenas_productos_raw` | EliminaciÃ³n de duplicados | 698 reseÃ±as duplicadas eliminadas |\n",
        "\n",
        "**Total despuÃ©s de transformaciones:** 64,474 registros transformados\n",
        "\n",
        "### Datos Cargados a ProducciÃ³n\n",
        "\n",
        "| Tabla Staging | Tabla ProducciÃ³n | Filas Cargadas | Mapeo de IDs |\n",
        "|---------------|------------------|----------------|--------------|\n",
        "| `categorias_raw` | `categorias` | 12 | âœ… Por nombre |\n",
        "| `metodos_pago_raw` | `metodos_pago` | 7 | âœ… Por nombre |\n",
        "| `usuarios_raw` | `usuarios` | 1,000 | âœ… Por dni/email |\n",
        "| `productos_raw` | `productos` | 36 | âœ… Por nombre |\n",
        "| `ordenes_raw` | `ordenes` | 10,000 | âŒ Sin mapeo |\n",
        "| `detalle_ordenes_raw` | `detalle_ordenes` | 10,000 | âŒ Sin mapeo |\n",
        "| `carrito_raw` | `carrito` | 5,000 | âŒ Sin mapeo |\n",
        "| `direcciones_envio_raw` | `direcciones_envio` | 1,000 | âŒ Sin mapeo |\n",
        "| `resenas_productos_raw` | `resenas_productos` | 6,474 | âŒ Sin mapeo |\n",
        "| `ordenes_metodos_pago_raw` | `ordenes_metodos_pago` | 10,000 | âŒ Sin mapeo |\n",
        "| `historial_pagos_raw` | `historial_pagos` | 10,000 | âŒ Sin mapeo |\n",
        "\n",
        "**Total a ProducciÃ³n:** 64,474 registros cargados en 11 tablas de producciÃ³n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Componentes TÃ©cnicos Utilizados\n",
        "\n",
        "### 1. Arquitectura de Capas (Staging â†’ ProducciÃ³n)\n",
        "\n",
        "**Capa Staging (Raw):**\n",
        "- Tablas sin primary keys ni foreign keys\n",
        "- Creadas con SQL directo (`create_staging_tables.sql`)\n",
        "- Almacenan datos crudos tal como vienen del CSV\n",
        "- Permiten anÃ¡lisis exploratorio sin restricciones\n",
        "\n",
        "**Capa ProducciÃ³n:**\n",
        "- Tablas con IDs autoincrementales, foreign keys y constraints\n",
        "- Creadas con SQLAlchemy ORM (`models.py`)\n",
        "- Datos transformados y validados\n",
        "- Integridad referencial garantizada\n",
        "\n",
        "### 2. PatrÃ³n Singleton\n",
        "- **`DBConnector`**: GestiÃ³n Ãºnica de conexiÃ³n a PostgreSQL\n",
        "  - MÃ©todo `get_raw_connection()`: Context manager para conexiones raw de psycopg2 (usado para COPY)\n",
        "- **`PathManager`**: GestiÃ³n centralizada de rutas del proyecto\n",
        "\n",
        "### 3. ConfiguraciÃ³n Centralizada\n",
        "- **`ETLConfig`**: Todos los parÃ¡metros configurables en un solo lugar\n",
        "  - `CSV_ENCODING = 'utf-8'` - Encoding de archivos CSV\n",
        "\n",
        "### 4. Transformaciones Aplicadas (`ETL/transformations.py`)\n",
        "- **EstandarizaciÃ³n de nombres**: `clean_column_name()` - Convierte camelCase a snake_case\n",
        "- **NormalizaciÃ³n de emails**: Elimina espacios, acentos, caracteres especiales\n",
        "- **EliminaciÃ³n de duplicados**: Por claves naturales (ej: usuario_id + producto_id)\n",
        "- **CÃ¡lculo de totales**: Recalcula totales de Ã³rdenes desde detalle_ordenes\n",
        "- **Validaciones numÃ©ricas**: Convierte valores negativos a 0\n",
        "\n",
        "### 5. Carga de Datos con COPY\n",
        "- **Staging**: `load_raw_data()` - Usa COPY para cargar datos crudos\n",
        "- **ProducciÃ³n**: `load_to_production()` - Usa pandas `to_sql()` con generaciÃ³n automÃ¡tica de IDs\n",
        "- **MÃ¡xima eficiencia**: COPY es el mÃ©todo mÃ¡s rÃ¡pido para cargar datos\n",
        "\n",
        "### 6. ResoluciÃ³n AutomÃ¡tica de Foreign Keys\n",
        "- **Mapeo de IDs**: Usa identificadores naturales (nombre, dni, email) para crear mapeos\n",
        "- **ResoluciÃ³n automÃ¡tica**: Convierte referencias de staging a IDs de producciÃ³n\n",
        "- **Orden de carga**: Respeta dependencias (tablas independientes primero)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Estructura de Archivos Ejecutados\n",
        "\n",
        "```\n",
        "Avance1/\n",
        "â”œâ”€â”€ main.py                    # Orquestador principal del ETL completo\n",
        "â”‚\n",
        "â”œâ”€â”€ Models/\n",
        "â”‚   â”œâ”€â”€ create_tables.py      # CreaciÃ³n de tablas (staging y producciÃ³n)\n",
        "â”‚   â”œâ”€â”€ create_staging_tables.sql  # SQL para crear tablas staging\n",
        "â”‚   â”œâ”€â”€ models.py              # Modelos ORM de producciÃ³n (11 tablas)\n",
        "â”‚   â””â”€â”€ enums.py               # Enumeraciones (EstadoOrden, EstadoPago)\n",
        "â”‚\n",
        "â”œâ”€â”€ ETL/\n",
        "â”‚   â”œâ”€â”€ load_raw_data.py      # Paso 2: Carga datos crudos a staging\n",
        "â”‚   â”œâ”€â”€ transformations.py    # Paso 4: Transformaciones sobre staging\n",
        "â”‚   â”œâ”€â”€ load_to_production.py # Paso 5-6: Carga a producciÃ³n y resuelve FKs\n",
        "â”‚   â””â”€â”€ pipeline.py            # Pipeline modular (ejecuciÃ³n por pasos)\n",
        "â”‚\n",
        "â””â”€â”€ Utils/\n",
        "    â”œâ”€â”€ path_manager.py       # GestiÃ³n de rutas (Singleton)\n",
        "    â”œâ”€â”€ config.py              # ConfiguraciÃ³n centralizada\n",
        "    â””â”€â”€ clean_column_name.py  # TransformaciÃ³n de nombres\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Validaciones y Constraints Aplicados\n",
        "\n",
        "### Transformaciones en Staging (antes de producciÃ³n)\n",
        "- **NormalizaciÃ³n de emails**: EliminaciÃ³n de espacios, acentos, caracteres especiales\n",
        "- **EliminaciÃ³n de duplicados**: ReseÃ±as duplicadas por (usuario_id, producto_id)\n",
        "- **CÃ¡lculo de totales**: Recalcula totales de Ã³rdenes desde detalle_ordenes\n",
        "- **Validaciones numÃ©ricas**: Convierte valores negativos a 0 (precios, stock, cantidades, montos)\n",
        "- **Trim de campos de texto**: Elimina espacios al inicio y final\n",
        "\n",
        "### CheckConstraints en ProducciÃ³n (Validaciones NumÃ©ricas)\n",
        "- `precio >= 0` (productos)\n",
        "- `stock >= 0` (productos)\n",
        "- `total >= 0` (ordenes)\n",
        "- `cantidad >= 0` (detalle_ordenes, carrito)\n",
        "- `precio_unitario >= 0` (detalle_ordenes)\n",
        "- `monto_pagado >= 0` (ordenes_metodos_pago)\n",
        "- `monto >= 0` (historial_pagos)\n",
        "- `calificacion >= 1 AND calificacion <= 5` (resenas_productos)\n",
        "\n",
        "### Enums Nativos de PostgreSQL\n",
        "- **`estado_orden`**: Pendiente, Enviado, Completado, Cancelado\n",
        "- **`estado_pago`**: Procesando, Pagado, Fallido, Reembolsado\n",
        "\n",
        "### Foreign Keys y Integridad Referencial\n",
        "- Todas las foreign keys se resuelven automÃ¡ticamente durante la carga\n",
        "- Mapeo de IDs usando identificadores naturales (nombre, dni, email)\n",
        "- Orden de carga respeta dependencias entre tablas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Resultado Final\n",
        "\n",
        "âœ… **11 tablas staging creadas exitosamente** (SQL directo, sin IDs ni FKs)\n",
        "\n",
        "âœ… **11 tablas de producciÃ³n creadas exitosamente** (ORM, con IDs, FKs y constraints)\n",
        "\n",
        "âœ… **11 archivos CSV procesados exitosamente**\n",
        "\n",
        "âœ… **55,227 registros cargados a staging** (datos crudos)\n",
        "\n",
        "âœ… **64,474 registros transformados** (despuÃ©s de limpieza y transformaciones)\n",
        "\n",
        "âœ… **64,474 registros cargados a producciÃ³n** (con IDs autoincrementales)\n",
        "\n",
        "âœ… **Transformaciones aplicadas:**\n",
        "   - 379 emails normalizados\n",
        "   - 1,000 totales de Ã³rdenes recalculados\n",
        "   - 698 reseÃ±as duplicadas eliminadas\n",
        "\n",
        "âœ… **Mapeos de IDs creados:** 4 tablas (categorias, metodos_pago, usuarios, productos)\n",
        "\n",
        "âœ… **Foreign keys resueltas automÃ¡ticamente** durante la carga\n",
        "\n",
        "âœ… **Todas las validaciones y constraints aplicados correctamente**\n",
        "\n",
        "âœ… **Integridad referencial mantenida mediante Foreign Keys**\n",
        "\n",
        "âœ… **Tipos de datos ajustados para preservar integridad semÃ¡ntica**\n",
        "\n",
        "## ðŸ”„ Ventajas del Nuevo Flujo con Staging\n",
        "\n",
        "1. **SeparaciÃ³n de responsabilidades**: Datos crudos vs datos transformados\n",
        "2. **AnÃ¡lisis exploratorio**: Puedes analizar datos crudos sin restricciones\n",
        "3. **Reprocesamiento**: FÃ¡cil reprocesar si hay errores\n",
        "4. **Trazabilidad**: Puedes comparar staging vs producciÃ³n\n",
        "5. **Mejores prÃ¡cticas**: Sigue el patrÃ³n estÃ¡ndar de Data Warehousing\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
